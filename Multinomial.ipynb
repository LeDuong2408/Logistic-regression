{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28395</td>\n",
       "      <td>610.291</td>\n",
       "      <td>208.178117</td>\n",
       "      <td>173.888747</td>\n",
       "      <td>1.197191</td>\n",
       "      <td>0.549812</td>\n",
       "      <td>28715</td>\n",
       "      <td>190.141097</td>\n",
       "      <td>0.763923</td>\n",
       "      <td>0.988856</td>\n",
       "      <td>0.958027</td>\n",
       "      <td>0.913358</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.834222</td>\n",
       "      <td>0.998724</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28734</td>\n",
       "      <td>638.018</td>\n",
       "      <td>200.524796</td>\n",
       "      <td>182.734419</td>\n",
       "      <td>1.097356</td>\n",
       "      <td>0.411785</td>\n",
       "      <td>29172</td>\n",
       "      <td>191.272751</td>\n",
       "      <td>0.783968</td>\n",
       "      <td>0.984986</td>\n",
       "      <td>0.887034</td>\n",
       "      <td>0.953861</td>\n",
       "      <td>0.006979</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.909851</td>\n",
       "      <td>0.998430</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29380</td>\n",
       "      <td>624.110</td>\n",
       "      <td>212.826130</td>\n",
       "      <td>175.931143</td>\n",
       "      <td>1.209713</td>\n",
       "      <td>0.562727</td>\n",
       "      <td>29690</td>\n",
       "      <td>193.410904</td>\n",
       "      <td>0.778113</td>\n",
       "      <td>0.989559</td>\n",
       "      <td>0.947849</td>\n",
       "      <td>0.908774</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.825871</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30008</td>\n",
       "      <td>645.884</td>\n",
       "      <td>210.557999</td>\n",
       "      <td>182.516516</td>\n",
       "      <td>1.153638</td>\n",
       "      <td>0.498616</td>\n",
       "      <td>30724</td>\n",
       "      <td>195.467062</td>\n",
       "      <td>0.782681</td>\n",
       "      <td>0.976696</td>\n",
       "      <td>0.903936</td>\n",
       "      <td>0.928329</td>\n",
       "      <td>0.007017</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.861794</td>\n",
       "      <td>0.994199</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30140</td>\n",
       "      <td>620.134</td>\n",
       "      <td>201.847882</td>\n",
       "      <td>190.279279</td>\n",
       "      <td>1.060798</td>\n",
       "      <td>0.333680</td>\n",
       "      <td>30417</td>\n",
       "      <td>195.896503</td>\n",
       "      <td>0.773098</td>\n",
       "      <td>0.990893</td>\n",
       "      <td>0.984877</td>\n",
       "      <td>0.970516</td>\n",
       "      <td>0.006697</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.941900</td>\n",
       "      <td>0.999166</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13606</th>\n",
       "      <td>42097</td>\n",
       "      <td>759.696</td>\n",
       "      <td>288.721612</td>\n",
       "      <td>185.944705</td>\n",
       "      <td>1.552728</td>\n",
       "      <td>0.765002</td>\n",
       "      <td>42508</td>\n",
       "      <td>231.515799</td>\n",
       "      <td>0.714574</td>\n",
       "      <td>0.990331</td>\n",
       "      <td>0.916603</td>\n",
       "      <td>0.801865</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.642988</td>\n",
       "      <td>0.998385</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13607</th>\n",
       "      <td>42101</td>\n",
       "      <td>757.499</td>\n",
       "      <td>281.576392</td>\n",
       "      <td>190.713136</td>\n",
       "      <td>1.476439</td>\n",
       "      <td>0.735702</td>\n",
       "      <td>42494</td>\n",
       "      <td>231.526798</td>\n",
       "      <td>0.799943</td>\n",
       "      <td>0.990752</td>\n",
       "      <td>0.922015</td>\n",
       "      <td>0.822252</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.676099</td>\n",
       "      <td>0.998219</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13608</th>\n",
       "      <td>42139</td>\n",
       "      <td>759.321</td>\n",
       "      <td>281.539928</td>\n",
       "      <td>191.187979</td>\n",
       "      <td>1.472582</td>\n",
       "      <td>0.734065</td>\n",
       "      <td>42569</td>\n",
       "      <td>231.631261</td>\n",
       "      <td>0.729932</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.918424</td>\n",
       "      <td>0.822730</td>\n",
       "      <td>0.006681</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.676884</td>\n",
       "      <td>0.996767</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13609</th>\n",
       "      <td>42147</td>\n",
       "      <td>763.779</td>\n",
       "      <td>283.382636</td>\n",
       "      <td>190.275731</td>\n",
       "      <td>1.489326</td>\n",
       "      <td>0.741055</td>\n",
       "      <td>42667</td>\n",
       "      <td>231.653247</td>\n",
       "      <td>0.705389</td>\n",
       "      <td>0.987813</td>\n",
       "      <td>0.907906</td>\n",
       "      <td>0.817457</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.668237</td>\n",
       "      <td>0.995222</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13610</th>\n",
       "      <td>42159</td>\n",
       "      <td>772.237</td>\n",
       "      <td>295.142741</td>\n",
       "      <td>182.204716</td>\n",
       "      <td>1.619841</td>\n",
       "      <td>0.786693</td>\n",
       "      <td>42600</td>\n",
       "      <td>231.686223</td>\n",
       "      <td>0.788962</td>\n",
       "      <td>0.989648</td>\n",
       "      <td>0.888380</td>\n",
       "      <td>0.784997</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.616221</td>\n",
       "      <td>0.998180</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13611 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
       "0      28395    610.291       208.178117       173.888747      1.197191   \n",
       "1      28734    638.018       200.524796       182.734419      1.097356   \n",
       "2      29380    624.110       212.826130       175.931143      1.209713   \n",
       "3      30008    645.884       210.557999       182.516516      1.153638   \n",
       "4      30140    620.134       201.847882       190.279279      1.060798   \n",
       "...      ...        ...              ...              ...           ...   \n",
       "13606  42097    759.696       288.721612       185.944705      1.552728   \n",
       "13607  42101    757.499       281.576392       190.713136      1.476439   \n",
       "13608  42139    759.321       281.539928       191.187979      1.472582   \n",
       "13609  42147    763.779       283.382636       190.275731      1.489326   \n",
       "13610  42159    772.237       295.142741       182.204716      1.619841   \n",
       "\n",
       "       Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
       "0          0.549812       28715     190.141097  0.763923  0.988856   0.958027   \n",
       "1          0.411785       29172     191.272751  0.783968  0.984986   0.887034   \n",
       "2          0.562727       29690     193.410904  0.778113  0.989559   0.947849   \n",
       "3          0.498616       30724     195.467062  0.782681  0.976696   0.903936   \n",
       "4          0.333680       30417     195.896503  0.773098  0.990893   0.984877   \n",
       "...             ...         ...            ...       ...       ...        ...   \n",
       "13606      0.765002       42508     231.515799  0.714574  0.990331   0.916603   \n",
       "13607      0.735702       42494     231.526798  0.799943  0.990752   0.922015   \n",
       "13608      0.734065       42569     231.631261  0.729932  0.989899   0.918424   \n",
       "13609      0.741055       42667     231.653247  0.705389  0.987813   0.907906   \n",
       "13610      0.786693       42600     231.686223  0.788962  0.989648   0.888380   \n",
       "\n",
       "       Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \\\n",
       "0         0.913358      0.007332      0.003147      0.834222      0.998724   \n",
       "1         0.953861      0.006979      0.003564      0.909851      0.998430   \n",
       "2         0.908774      0.007244      0.003048      0.825871      0.999066   \n",
       "3         0.928329      0.007017      0.003215      0.861794      0.994199   \n",
       "4         0.970516      0.006697      0.003665      0.941900      0.999166   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "13606     0.801865      0.006858      0.001749      0.642988      0.998385   \n",
       "13607     0.822252      0.006688      0.001886      0.676099      0.998219   \n",
       "13608     0.822730      0.006681      0.001888      0.676884      0.996767   \n",
       "13609     0.817457      0.006724      0.001852      0.668237      0.995222   \n",
       "13610     0.784997      0.007001      0.001640      0.616221      0.998180   \n",
       "\n",
       "          Class  \n",
       "0         SEKER  \n",
       "1         SEKER  \n",
       "2         SEKER  \n",
       "3         SEKER  \n",
       "4         SEKER  \n",
       "...         ...  \n",
       "13606  DERMASON  \n",
       "13607  DERMASON  \n",
       "13608  DERMASON  \n",
       "13609  DERMASON  \n",
       "13610  DERMASON  \n",
       "\n",
       "[13611 rows x 17 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_bean = pd.read_csv('F:/University_HCMUTE/N3_HK2/AIOT/GiuaKy/Dry_Beans_Dataset.csv')\n",
    "df_bean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bean.Class = df_bean['Class'].map({'SEKER': 0, 'BARBUNYA': 1, 'BOMBAY': 2, 'CALI': 3, 'HOROZ': 4, 'SIRA': 5, 'DERMASON': 6})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_bean = df_bean['Class']\n",
    "data_bean = df_bean.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "scaler = StandardScaler()\n",
    "\n",
    "data_bean = scaler.fit_transform(data_bean)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_bean, goal_bean, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Logistic Regression Mutilnomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(z):\n",
    "    z -= np.max(z, axis=1, keepdims=True)\n",
    "    exp_sum = np.sum(np.exp(z), axis=1, keepdims=True)\n",
    "    return np.exp(z) / exp_sum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_label(labels, num_classes):\n",
    "    return np.eye(num_classes)[labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12224    6\n",
      "5212     3\n",
      "13374    6\n",
      "5680     4\n",
      "1890     0\n",
      "        ..\n",
      "10793    6\n",
      "914      0\n",
      "5840     4\n",
      "6593     4\n",
      "9725     5\n",
      "Name: Class, Length: 2723, dtype: int64\n",
      "[[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)\n",
    "y_one_hot = one_hot_label(y_test, 7)\n",
    "print(y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features, weights):\n",
    "    fc = np.dot(features, weights.T)\n",
    "    return softmax(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(features, labels, weights, learning_rate):\n",
    "    mu_i = predict(features, weights)\n",
    "    y_i = one_hot_label(labels, len(weights))\n",
    "    weights = weights - learning_rate * np.dot((mu_i - y_i).T, features)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features, labels, num_classes, learning_rate, iter):\n",
    "    num_features = features.shape[1]\n",
    "    weights = np.zeros((num_classes, num_features))  \n",
    "    for i in range(iter):\n",
    "        weights = gradient_descent(features, labels, weights, learning_rate)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_unique =  len(np.unique(y_test))\n",
    "w = train(x_train, y_train, value_unique, learning_rate = 0.01, iter= 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-21.66589945   8.61279108   9.3386126  -30.98909909  30.62302761\n",
      "  -53.33909321 -20.81544894  -9.96607696  -2.87828271  10.57553479\n",
      "   -8.70333407 -12.00567278 -62.32538336  10.52368142  -2.13714249\n",
      "   17.28802347]\n",
      " [ -0.16190752   3.66870356 -25.44141869  37.81127865 -15.67862579\n",
      "  -21.41698445   1.97476477   3.87351356   1.70549756  -7.66111433\n",
      "   -9.59676249   3.17927162   9.43651715 -69.86717449   1.03568105\n",
      "    8.10662472]\n",
      " [ 88.21997172   0.48661749  -6.73894373  19.59447159  -6.23871914\n",
      "    3.54602549  89.62220279   4.29151277   4.17501275  -9.96433173\n",
      "   23.43762871   8.49293392 107.09225455  22.06897149   8.05455951\n",
      "    8.75530377]\n",
      " [ -5.0980132   -1.89556048  30.16594419   1.78189747 -25.85173101\n",
      "   21.46002879  -6.27911822  21.40756588   2.00873723  -3.11506171\n",
      "    6.27850884  -7.52242852 -23.66800951  16.89105555 -13.53906277\n",
      "   -5.64724961]\n",
      " [-22.86675668  27.12743655   2.0004242  -18.43561287  45.08040134\n",
      "  -16.34246366 -20.08667198 -14.2764909   -0.40376458   5.22489011\n",
      "   -7.14855438  -1.35916338 -11.64772625   7.82776917   7.26015844\n",
      "  -15.60070023]\n",
      " [-48.02630251 -47.55063168  -0.84469232   0.43954585  10.40940771\n",
      "    4.8482964  -53.10281918  -0.24157933  -1.50639612   2.06761153\n",
      "  -13.38431691   2.60490304 -56.07827458 -37.17148437   5.33949737\n",
      "  -10.65412104]\n",
      " [  9.59890765   9.55064347  -8.47992626 -10.2024816  -38.34376073\n",
      "   61.24419064   8.68709076  -5.08844502  -3.10080413   2.87247135\n",
      "    9.11683031   6.61015609  37.19062199  49.72718123  -6.01369111\n",
      "   -2.24788107]]\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9114946749908189\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "bean_pred = predict(x_test, w)\n",
    "bean_pred = np.argmax(bean_pred, axis = 1)\n",
    "act = accuracy_score(y_test, bean_pred)\n",
    "print(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[405   0   0   1   0   8  11]\n",
      " [  2 241   0  18   1   5   0]\n",
      " [  0   0 102   0   0   0   0]\n",
      " [  2  10   2 303   3   3   0]\n",
      " [  0   1   0   7 353  23   6]\n",
      " [ 14   0   0   2   1 408  94]\n",
      " [  6   0   0   0   4  17 670]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_test, bean_pred)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=5000, multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=5000, multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=5000, multi_class='multinomial')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_bean = LogisticRegression(max_iter=5000, multi_class='multinomial')\n",
    "model_bean.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9272860815277267\n"
     ]
    }
   ],
   "source": [
    "y4_pred = model_bean.predict(x_test)\n",
    "act = accuracy_score(y_test, y4_pred)\n",
    "print(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[403   4   0   0   1  16   4]\n",
      " [  1 238   0  14   0   5   0]\n",
      " [  0   0  92   0   0   0   0]\n",
      " [  0   7   0 289   5   6   0]\n",
      " [  0   1   0   9 370   6   6]\n",
      " [  7   0   0   2   8 444  61]\n",
      " [ 11   0   0   0   2  50 661]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y4_pred)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test email spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_email = pd.read_csv(\"F:/University_HCMUTE/N3_HK2/AIOT/GiuaKy/emails.csv\")\n",
    "goal = df_email.Prediction\n",
    "data = df_email.drop(['Prediction', 'Email No.'], axis='columns')\n",
    "x1, x2, y1, y2 = train_test_split(data, goal, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_unique =  len(np.unique(y2))\n",
    "w_email = train(x1, y1, 2, learning_rate= 0.01, iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3311.40264502  3244.55933914  3541.01050278 ...    11.90501408\n",
      "   -244.76516367    24.58318136]\n",
      " [-3311.40264502 -3244.55933914 -3541.01050278 ...   -11.90501408\n",
      "    244.76516367   -24.58318136]]\n"
     ]
    }
   ],
   "source": [
    "print(w_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_email = predict(x2, w_email)\n",
    "y_pred_email = np.argmax(y_pred_email, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8995169082125604\n"
     ]
    }
   ],
   "source": [
    "act = accuracy_score(y2, y_pred_email)\n",
    "print(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_email(email_input):\n",
    "    email_array = np.zeros(3000)\n",
    "    words = email_input.split(' ')\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word in data.columns:\n",
    "            index = data.columns.get_loc(word) #lay vi tri cot co tu do\n",
    "            email_array[index] += 1\n",
    "    email_array = email_array.reshape(1, -1)\n",
    "    return email_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_content = \"I think Donk is insanely talented for his age but he needs to be more mature\"\n",
    "email_features = split_email(email_content)\n",
    "email_pred = predict(email_features, w_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email nÃ y Ä‘Æ°á»£c dá»± Ä‘oÃ¡n lÃ  khÃ´ng spam.\n"
     ]
    }
   ],
   "source": [
    "email_pred = predict(email_features, w_email)\n",
    "email_pred = np.argmax(email_pred, axis=1)\n",
    "# In káº¿t quáº£ dá»± Ä‘oÃ¡n\n",
    "if email_pred >= 0.5:\n",
    "    print(\"Email nÃ y Ä‘Æ°á»£c dá»± Ä‘oÃ¡n lÃ  spam.\")\n",
    "else:\n",
    "    print(\"Email nÃ y Ä‘Æ°á»£c dá»± Ä‘oÃ¡n lÃ  khÃ´ng spam.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
